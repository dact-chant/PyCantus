{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d62b763",
   "metadata": {},
   "source": [
    "# How the CantusCorpus 1.0 dataset was prepared\n",
    "This notebook documents how scraped Cantus Index data were modified (cleaned) before being exported as a dataset.  \n",
    "This Jupyter notebook mainly documents how CantusCorpus 1.0 was constructed from scrapes of the Cantus Index database network from May 2025.  \n",
    "In case anyone wants to scrape their (newer) data, e.g. via scripts from the `scraping` directory, this code can be used. \n",
    "It just needs the proper paths of the used files to be set and then some 'May 2025 CantusCorpus 1.0' specific steps to be changed or skipped.\n",
    "  \n",
    "We are providing two CSV files as a dataset:  \n",
    "  - chants\n",
    "  - sources\n",
    "  \n",
    "Main steps taken:\n",
    "- Join all chant files by genre into one file\n",
    "- Discard newlines from field values (esp. full text for strophic chants)\n",
    "- Discard duplicates in chantlinks\n",
    "- Genre standardisation based on the genre list in CI from which those records were from (issues only around Tp...)\n",
    "- Discard data (from chants and sources), where for sources we cannot collect additional info\n",
    "- Add a numerical century to sources\n",
    "- Inspect duplicate sources: discard and unify duplicates\n",
    "  \n",
    "Finally, we are adding some basic statistics about the just-constructed dataset in the `dataset_stats.ipynb` jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec4d3488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df1619a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANTS_DIR_PATH = 'cantuscorpus_1.0/chants_by_genre' # Rename to fit your directory structure or fit your structure into this\n",
    "SOURCES_CSV_PATH = 'cantuscorpus_1.0/scraped_sources.csv' # Rename to fit your directory structure or fit your structure into this\n",
    "\n",
    "FINAL_CHANTS_CSV_PATH = 'cantuscorpus_1.0/chants.csv' # Rename to fit your directory structure or fit your structure into this\n",
    "FINAL_SOURCES_CSV_PATH = 'cantuscorpus_1.0/sources.csv' # Rename to fit your directory structure or fit your structure into this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d39743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read static files\n",
    "feast =pd.read_csv('cantuscorpus_1.0/static/feast.csv', dtype={'feast_code' : str})\n",
    "genre = pd.read_csv('cantuscorpus_1.0/static/genre.csv')\n",
    "office = pd.read_csv('cantuscorpus_1.0/static/office.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43503c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = pd.read_csv(SOURCES_CSV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd605969",
   "metadata": {},
   "source": [
    "# Chants\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5be6e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of genre files: 106\n",
      "number of chant records - no processing: 1005793\n"
     ]
    }
   ],
   "source": [
    "# Concatenate chants data (chant records are in CSV files by genre)\n",
    "concat_chants_files = glob.glob(CHANTS_DIR_PATH + '/*.csv')\n",
    "chants_dfs_dict = {\n",
    "    os.path.splitext(os.path.basename(file))[0] : pd.read_csv(file,  dtype=str) \n",
    "    for file in concat_chants_files\n",
    "    }\n",
    "\n",
    "# Clean full_texts\n",
    "for file, df in chants_dfs_dict.items():\n",
    "    df['full_text'] = df['full_text'].str.replace('\\n', ' ').str.replace('\\r', '')\n",
    "    df['incipit'] = df['incipit'].str.replace('\\n', ' ').str.replace('\\r', '')\n",
    "    df['volpiano'] = df['volpiano'].str.replace('\\n', ' ').str.replace('\\r', '')\n",
    "chants = pd.concat(chants_dfs_dict, ignore_index=True)\n",
    "\n",
    "# Store 'I am from Cantus Index genre lists XY' info\n",
    "non_empty_genre = 0\n",
    "for file, df in chants_dfs_dict.items():\n",
    "    if len(df) > 0:\n",
    "        non_empty_genre += 1\n",
    "    df['genre_file'] = file\n",
    "    df['full_text'] = df['full_text'].str.replace('\\n', ' ').str.replace('\\r', '')\n",
    "    \n",
    "print('number of genre files:', non_empty_genre)\n",
    "\n",
    "chants_genre_file = pd.concat(chants_dfs_dict, ignore_index=True)\n",
    "\n",
    "print('number of chant records - no processing:', len(chants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35d66966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of not unique records in chantlinks in data: 117100\n",
      "number of not unique rows in data: 117088\n",
      "number of not duplicit records with duplicit chantlink in data: 12\n"
     ]
    }
   ],
   "source": [
    "# Analyze duplicates\n",
    "print(\"number of not unique records in chantlinks in data:\", \n",
    "                len(chants[\"chantlink\"].value_counts()[lambda x: x > 1].index))\n",
    "print(\"number of not unique rows in data:\", \n",
    "                len(chants) - len(chants.drop_duplicates()))\n",
    "print(\"number of not duplicit records with duplicit chantlink in data:\", \n",
    "                len(chants.drop_duplicates()) - len(chants['chantlink'].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aff144d",
   "metadata": {},
   "source": [
    "Here comes May 2025 CantusCorpus 1.0 specific piece of work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6fc4ae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chants records without duplicates: 888693\n"
     ]
    }
   ],
   "source": [
    "# Chants without duplicates\n",
    "# turns out those 12 were records of AH49403 vs ah49403 so we gonna keep the lowercased version as being standard...\n",
    "\n",
    "# Drop fully duplicated rows\n",
    "df = chants.drop_duplicates()\n",
    "\n",
    "# Find `chantlink` values that are still duplicated\n",
    "dup_chantlinks = df['chantlink'].value_counts()[lambda x: x > 1].index\n",
    "\n",
    "# Keep only rows with duplicated chantlink **and** cantus_id starting with lowercase letter\n",
    "mask = (\n",
    "    df['chantlink'].isin(dup_chantlinks) & \n",
    "    df['cantus_id'].str.match(r'^[a-z]')\n",
    ")\n",
    "\n",
    "# Keep rows that are either:\n",
    "# - Not part of duplicated chantlinks\n",
    "# - Or part of duplicated chantlinks AND their cantus_id starts with lowercase\n",
    "chants = df[~df['chantlink'].isin(dup_chantlinks) | mask]\n",
    "print(\"number of chants records without duplicates:\", len(chants))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a214e17",
   "metadata": {},
   "source": [
    "### Genre\n",
    "Searching for an overview of how various genre values are.  \n",
    "If it's too messy, we can try to standardise it with the help of the \"from this CI genre list\" value we have for each chant record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da19051e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres present in data and not in CI genre list:\n",
      "{'Ant3', 'Am7', 'All1', 'Gr5', 'Comm+', 'Gr2', 'R8', 'AllV', 'Tr2', 'a4', 'Am9', 'Am1', 'La', 'All-V', 'R9', 'V12', 'R5', 'All6', 'Ant4', 'a5+', 'R12', 'R3+', 'Varia', 'a5', 'Ant2', 'A8', 'V123', 'Be', 'Gr3V', 'Ab+', 'A6', 'Im', 'Com', 'V122', 'R3', 'V21', 'a2', 'R11', 'V2', 'V5', 'V13', 'V7', 'V151', 'All2', 'R7', 'Gr-V', 'Vs', 'GRCV', 'a+', 'V152', 'Am4', 'R4', 'LDM', 'R15', 'Intr', 'R6', 'An', 'All5', 'V9', 'a1', 'V3+', 'Gr1', 'A14', 'V1', 'All3', 'V14', '\\xa0?', 'Gr+', 'All+', 'TrV', nan, 'Gr3', 'M', 'Comm', 'RespV', 'Resp', 'Tr4', 'A12', 'An+', 'V121', 'Tr', 'V+', 'Ant1', 'a2+', 'R14', 'r', 'All1V', 'Am6', 'V3', 'Varia/A', 'CommV', 'Gr2V', 'R1', 'Off', 'A10', 'Aproc', 'R+', 'R13', 'Am8', 'a3+', 'Seq', 'Am3', 'Tr3', 'V126', 'a', 'All-1', 'HYMNV', 'Gr4', 'Dox', 'V32', 'A11', 'Gr4V', 'Trop', 'IntrV', '[a3]', 'Ant', 'V10', 'V4', 'a3', 'V15', 'V6', 'Ap+', 'LG', 'V31', 'Am5', 'A9', 'Tr1', 'Ant/Resp', 'Am2', 'All', 'Am', 'V8', 'V124', 'Sequ', 'Off+', 'AntV', 'R2', 'All-2', 'Hymn', 'Ap', 'Ab', 'V33', 'A7', 'V11', 'Am+', 'Gr1V', 'A13', 'R10', 'Ru', 'OffV'}\n"
     ]
    }
   ],
   "source": [
    "genres_in_data = set(chants['genre'])\n",
    "print('Genres present in data and not in CI genre list:')\n",
    "print(genres_in_data.difference(set(genre['genre_name'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d07c65",
   "metadata": {},
   "source": [
    "Because we consider **genre** to be an important information, it makes sense to standardise it to CI values with the knowledge of in what genre list they are displayed in CI...  \n",
    "This is a step where we are changing information from scraped JSON for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3e01efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just ensure we got genre value V and not [GV] value, that is already an empty list on the CI front-end\n",
    "# Drop [GV] that are no longer displayed in CI (duplicates of V)\n",
    "# This is done so we do not accidentally take [GV] somewhere\n",
    "chants_genre_file = chants_genre_file[chants_genre_file['genre_file'] != '[GV]']\n",
    "\n",
    "# Remove duplicates in chants_genre_file based on chantlink - so we are sure we have clear mapping\n",
    "chants_genre_file = chants_genre_file.drop_duplicates(subset='chantlink', keep='first')\n",
    "\n",
    "# For nonstandard values of genre we use value of genre_file instead\n",
    "# Identify unacceptable genres\n",
    "mask = ~chants['genre'].isin(set(genre['genre_name']))\n",
    "\n",
    "# Create a mapping from chantlink to genre_file\n",
    "genre_substitution_map = chants_genre_file.set_index('chantlink')['genre_file']\n",
    "\n",
    "# Replace invalid genres using the mapping\n",
    "chants.loc[mask, 'genre'] = chants.loc[mask, 'chantlink'].map(genre_substitution_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e1eabbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres present in data and not in CI genre list after cleaning:\n",
      "{'[unknown]'}\n"
     ]
    }
   ],
   "source": [
    "genres_in_data = set(chants['genre'])\n",
    "print('Genres present in data and not in CI genre list after cleaning:')\n",
    "print(genres_in_data.difference(set(genre['genre_name'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4054ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets substitute 'unknown' with '[?]' which is the original name of the list they are from\n",
    "chants.loc[:, 'genre'] = chants['genre'].str.replace('[unknown]', '[?]', regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0989d3b7",
   "metadata": {},
   "source": [
    "### Office\n",
    "This is simply to be aware of how non-standardised this field is. There is not much to do about it besides passing the information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85b0faf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offices present in data and not in CD office list:\n",
      "\tnumeric: ['977', '970', '966', '963', '972', '980', '967', '969', '1003', '1004', '968', '979', '964', '978', '974', '971', '1002', '965', '975', '976']\n",
      "\tother: ['Q&Q', 'MN', 'MH', 'S&O', 'P&S', 'DU&D', 'C2', 'Noc', 'MASS', nan, 'Pec', 'AL']\n"
     ]
    }
   ],
   "source": [
    "offices_in_data = set(chants['office'])\n",
    "print('Offices present in data and not in CD office list:')\n",
    "numeric, alpha = [], []\n",
    "for o in offices_in_data.difference(set(office['name'])):\n",
    "    if str(o).isdigit():\n",
    "        numeric.append(o)\n",
    "    else:\n",
    "        alpha.append(o)\n",
    "print('\\tnumeric:', numeric)\n",
    "print('\\tother:', alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce49fb72",
   "metadata": {},
   "source": [
    "Hard to say if MI (from CDB) and MASS (from SEMM and others) mean really always the same thing or not...  \n",
    "In this, we are sticking to our policy of \"being downstream\", and so we would let the data be as they are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a859ec",
   "metadata": {},
   "source": [
    "Numeric values are coming from the Hungarian Chant Database.  \n",
    "When looking at those records on their web, we found out that they are using pretty standard valaues - and the problem is somewhere in drupal export (those numbers are numbers of drupal nodes...).  \n",
    "It would be a pity to left it as it is when we have the \"ground true\" comming from Hungarian Chantd database web and it is easy to restore the CI values of office, although not always 'chnaging number into string' really brings standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d2df1531",
   "metadata": {},
   "outputs": [],
   "source": [
    "hunchant_office = pd.read_csv('cantuscorpus_1.0/static/hunchant_office.csv', dtype={'drupal_node' : str})\n",
    "\n",
    "merged = chants.merge(\n",
    "    hunchant_office[['drupal_node', 'CI_suggestion_string', 'office_string']],\n",
    "    how='left',\n",
    "    left_on='office',\n",
    "    right_on='drupal_node'\n",
    ")\n",
    "\n",
    "merged['office_updated'] = merged.apply(\n",
    "    lambda row: row['CI_suggestion_string']\n",
    "    if pd.notna(row['CI_suggestion_string'])\n",
    "    else (row['office_string'] if pd.notna(row['office_string']) else row['office']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "chants.loc[:, 'office'] = merged['office_updated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "239b8027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offices present in data and not in CDB office list:\n",
      "\tnumeric: []\n",
      "\tother: ['CC', 'Q&Q', 'Inv', 'S&O', 'MASS', 'AL', 'MN', 'DU&D', 'An', nan, 'P&S', 'Comm', 'Noc', 'C2', 'MH', 'Wsac', 'Pec']\n"
     ]
    }
   ],
   "source": [
    "# Check what we solved\n",
    "offices_in_data = set(chants['office'])\n",
    "print('Offices present in data and not in CDB office list:')\n",
    "numeric, alpha = [], []\n",
    "for o in offices_in_data.difference(set(office['name'])):\n",
    "    if str(o).isdigit():\n",
    "        numeric.append(o)\n",
    "    else:\n",
    "        alpha.append(o)\n",
    "print('\\tnumeric:', numeric)\n",
    "print('\\tother:', alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f4076",
   "metadata": {},
   "source": [
    "### Melody overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c11f1927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of melody_ids records: 0\n",
      "Number of melody_id values in data: 0\n"
     ]
    }
   ],
   "source": [
    "print('Number of melody_ids records:', len(chants['melody_id'].dropna()))\n",
    "print('Number of melody_id values in data:', len(set(chants['melody_id'].dropna())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "24d6d95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 most frequent modes in data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mode\n",
       "*     121318\n",
       "8      89894\n",
       "1      79870\n",
       "7      59778\n",
       "4      44864\n",
       "2      43350\n",
       "3      30378\n",
       "5      23932\n",
       "r      22351\n",
       "?      20456\n",
       "6      18895\n",
       "6T      4460\n",
       "4T      3900\n",
       "2T      3110\n",
       "1S      3047\n",
       "1T      2244\n",
       "8S      1427\n",
       "2S      1210\n",
       "3S      1186\n",
       "6S      1102\n",
       "5S       986\n",
       "7S       936\n",
       "4S       805\n",
       "G        738\n",
       "8*       673\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('25 most frequent modes in data:')\n",
    "chants['mode'].value_counts().head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f325e0",
   "metadata": {},
   "source": [
    "### Feasts\n",
    "Since no clear standard exists on filed of feasts right now, we can provide only this simple numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "51de0b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of feasts recognized in CI list: 1794\n",
      "number of feast values in data: 2401\n"
     ]
    }
   ],
   "source": [
    "print('number of feasts recognized in CI list:', len(feast))\n",
    "print('number of feast values in data:', len(set(chants['feast'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54539be7",
   "metadata": {},
   "source": [
    "# Sources\n",
    "Just a quick look at scraped sources.  \n",
    "Problems with http -> https for databases where redirect works corectly so the scraper did not notice (vs MMMO).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86879aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTTP -> HTTPS\n",
    "# all databases moved to https even in API except musmed \n",
    "# (http in source data is a mistake, allowed thanks to redirection, in sources scraping)\n",
    "sources['srclink'] = sources['srclink'].apply(\n",
    "    lambda x: x if not isinstance(x, str) else (\n",
    "        x if x.startswith('http://musmed') else x.replace('http://', 'https://')\n",
    "    )\n",
    ")\n",
    "# Clean spaces in fields\n",
    "sources['siglum'] = sources['siglum'].str.strip()\n",
    "sources['title'] = sources['title'].str.strip()\n",
    "sources['provenance'] = sources['provenance'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d10965b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sources being scraped and not present in data: 0\n",
      "\n",
      "Number of sources being in data and not in scraped sources info: 30\n"
     ]
    }
   ],
   "source": [
    "# For how many sources mentioned in data we do not have source information scraped\n",
    "sources_in_data = set(chants['srclink'])\n",
    "scraped_sources = set(sources['srclink'])\n",
    "print('Number of sources being scraped and not present in data:', \n",
    "      len(scraped_sources.difference(sources_in_data)))\n",
    "print()\n",
    "print('Number of sources being in data and not in scraped sources info:', \n",
    "      len(sources_in_data.difference(scraped_sources)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5708f2d6",
   "metadata": {},
   "source": [
    "##### Very \"data version\" specific piece of code follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ced2879c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hispanica: 12\n",
      "https://musicahispanica.eu/source/25460\n",
      "https://musicahispanica.eu/source/25462\n",
      "https://musicahispanica.eu/source/25468\n",
      "https://musicahispanica.eu/source/25466\n",
      "https://musicahispanica.eu/source/25470\n",
      "https://musicahispanica.eu/source/25319\n",
      "https://musicahispanica.eu/source/25464\n",
      "https://musicahispanica.eu/source/25461\n",
      "https://musicahispanica.eu/source/25467\n",
      "https://musicahispanica.eu/source/25469\n",
      "https://musicahispanica.eu/source/25465\n",
      "https://musicahispanica.eu/source/25463\n",
      "FCB: 18\n",
      "https://cantusbohemiae.cz/source/9185\n",
      "https://cantusbohemiae.cz/source/10804\n",
      "https://cantusbohemiae.cz/source/9152\n",
      "https://cantusbohemiae.cz/source/9309\n",
      "https://cantusbohemiae.cz/source/2147\n",
      "https://cantusbohemiae.cz/source/9198\n",
      "https://cantusbohemiae.cz/source/22098\n",
      "https://cantusbohemiae.cz/source/22705\n",
      "https://cantusbohemiae.cz/source/9192\n",
      "https://cantusbohemiae.cz/source/9188\n",
      "https://cantusbohemiae.cz/source/21983\n",
      "https://cantusbohemiae.cz/source/11619\n",
      "https://cantusbohemiae.cz/source/2153\n",
      "https://cantusbohemiae.cz/source/22153\n",
      "https://cantusbohemiae.cz/source/4443\n",
      "https://cantusbohemiae.cz/source/22046\n",
      "https://cantusbohemiae.cz/source/22179\n",
      "https://cantusbohemiae.cz/source/9150\n",
      "others: 0\n"
     ]
    }
   ],
   "source": [
    "# Inspect those 30 troublemakers \n",
    "hispanica_once = []\n",
    "fontes_once = []\n",
    "others = []\n",
    "for trouble_source_URL in sources_in_data.difference(scraped_sources):\n",
    "    if 'hispanica' in trouble_source_URL:\n",
    "        hispanica_once.append(trouble_source_URL)\n",
    "    elif 'cantusbohemiae' in trouble_source_URL:\n",
    "        fontes_once.append(trouble_source_URL)\n",
    "    else:\n",
    "        others.append(trouble_source_URL)\n",
    "\n",
    "print('hispanica:', len(hispanica_once))\n",
    "for url in hispanica_once:\n",
    "    print(url)\n",
    "print('FCB:', len(fontes_once))\n",
    "for url in fontes_once:\n",
    "    print(url)\n",
    "print('others:', len(others))\n",
    "for url in others:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2253f11d",
   "metadata": {},
   "source": [
    "Those hispanica sources are all fragments of one manuscript and all are missing Shelfmark (-> siglum), but we can get that value directly from their chant records, where siglum is required field - we have to add these 12 sources manually before dataset realese. \n",
    "   \n",
    "\"E-BAR, Archivo Diocesano de Barbastro, Carp, nº 66: Frag. 4\"  \n",
    "\"E-BAR, Archivo Diocesano de Barbastro, Carp, nº 66: Frag. 7\"  \n",
    "\"E-BAR, Archivo Diocesano de Barbastro, Carp, nº 66: Frag. 12\"  \n",
    "\"E-BAR, Archivo Diocesano de Barbastro, Carp, nº 66: Frag. 10.2\"  \n",
    "\"E-BAR, Archivo Diocesano de Barbastro, Carp, nº 66: Frag. 6\"  \n",
    "\"E-BAR, Archivo Diocesano de Barbastro, Carp, nº 66: Frag. 5\"  \n",
    "\"E-BAR, Archivo Diocesano de Barbastro, Carp. nº 66: Frag. 2\"  \n",
    "\"E-BAR, Archivo Diocesano de Barbastro, Carp. nº 66: Frag. 3\"  \n",
    "\"E-BAR, Archivo Diocesano de Barbastro, Carp, nº 66: Frag. 11  \n",
    "\"E-BAR, Archivo Diocesano de Barbastro, Carp, nº 66: Frag. 9\"  \n",
    "\"E-BAR, Archivo Diocesano de Barbastro, Carp, nº 66: Frag. 10.1\"  \n",
    "\"E-BAR, Archivo Diocesano de Barbastro, Carp, nº 66: Frag. 8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5252d3b9",
   "metadata": {},
   "source": [
    "Those FCB source pages are returning 'Acces denied'...  \n",
    "Since we did not manage to get info about reason of this hidding, we decided to discard their chant records in case these sources were hidden due to some quality problems etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "27da7cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chant records before discarding problematic FCB sources: 888693\n",
      "number of chant records after discarding problematic FCB sources: 888110\n"
     ]
    }
   ],
   "source": [
    "print('number of chant records before discarding problematic FCB sources:', len(chants))\n",
    "for srclink in fontes_once:\n",
    "    # Discard \"FCB hidden sources\" records in chants\n",
    "    chants = chants[chants['srclink'] != srclink]\n",
    "print('number of chant records after discarding problematic FCB sources:', len(chants))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412cd866",
   "metadata": {},
   "source": [
    "### Duplicity in sources...?\n",
    "We want to have a look at how unique value siglum is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "777caf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "siglum\n",
      "PL-PŁsem MsEPl 12                                 2\n",
      "CZ-OLu M III 6                                    2\n",
      "SK-KRE 1625                                       2\n",
      "CZ-Pn XII A 24                                    2\n",
      "A-KN CCl 1018                                     2\n",
      "CZ-Pn XV A 10                                     2\n",
      "CZ-Pu VI G 3a                                     2\n",
      "P-LA Caixa 2, Fragmento 017                       2\n",
      "CZ-Pu XIV G 46                                    2\n",
      "SK-KRE Tom. 1, Fons 32, Fasc. 9, Nro. 83, 1583    2\n",
      "SK-KRE Tom. 2, Fons 41, Fasc. 1, Nro. 3, 1601     2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Look for duplicity in sigla\n",
    "print(sources['siglum'].value_counts()[lambda x : x > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ff45976c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chants in https://cantusplanus.pl/source/14457 PL-PŁsem MsEPl 12 : 2019\n",
      "number of chants in https://cantusplanus.pl/source/14458 PL-PŁsem MsEPl 12 : 1825\n",
      "---------------------\n",
      "number of chants in https://cantusbohemiae.cz/source/11616 CZ-OLu M III 6 : 467\n",
      "number of chants in https://hymnologica.cz/source/6983 CZ-OLu M III 6 : 156\n",
      "---------------------\n",
      "number of chants in https://cantus.sk/source/32083 SK-KRE 1625 : 4\n",
      "number of chants in https://cantus.sk/source/32224 SK-KRE 1625 : 3\n",
      "---------------------\n",
      "number of chants in https://cantusbohemiae.cz/source/33177 CZ-Pn XII A 24 : 865\n",
      "number of chants in https://hymnologica.cz/source/10619 CZ-Pn XII A 24 : 16\n",
      "---------------------\n",
      "number of chants in https://cantusdatabase.org/source/123616 A-KN CCl 1018 : 2776\n",
      "number of chants in https://austriamanus.org/source/3620 A-KN CCl 1018 : 21\n",
      "---------------------\n",
      "number of chants in https://cantusbohemiae.cz/source/28509 CZ-Pn XV A 10 : 2884\n",
      "number of chants in https://hymnologica.cz/source/47 CZ-Pn XV A 10 : 14\n",
      "---------------------\n",
      "number of chants in https://cantusbohemiae.cz/source/9147 CZ-Pu VI G 3a : 875\n",
      "number of chants in https://hymnologica.cz/source/5364 CZ-Pu VI G 3a : 79\n",
      "---------------------\n",
      "number of chants in https://pemdatabase.eu/source/46528 P-LA Caixa 2, Fragmento 017 : 8\n",
      "number of chants in https://musicahispanica.eu/source/62316 P-LA Caixa 2, Fragmento 017 : 8\n",
      "---------------------\n",
      "number of chants in https://cantusbohemiae.cz/source/9194 CZ-Pu XIV G 46 : 364\n",
      "number of chants in https://hymnologica.cz/source/5366 CZ-Pu XIV G 46 : 3\n",
      "---------------------\n",
      "number of chants in https://cantus.sk/source/32332 SK-KRE Tom. 1, Fons 32, Fasc. 9, Nro. 83, 1583 : 6\n",
      "number of chants in https://cantus.sk/source/32333 SK-KRE Tom. 1, Fons 32, Fasc. 9, Nro. 83, 1583 : 4\n",
      "---------------------\n",
      "number of chants in https://cantus.sk/source/32575 SK-KRE Tom. 2, Fons 41, Fasc. 1, Nro. 3, 1601 : 11\n",
      "number of chants in https://cantus.sk/source/32574 SK-KRE Tom. 2, Fons 41, Fasc. 1, Nro. 3, 1601 : 2\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "# Lets inspect them \n",
    "for siglum in sources['siglum'].value_counts()[lambda x : x > 1].index:\n",
    "    srclinks = list(sources[sources['siglum'] == siglum]['srclink'])\n",
    "    srclink1 = srclinks[0]\n",
    "    print('number of chants in', srclink1, siglum, ':', len(chants[chants['srclink'] == srclink1]))\n",
    "    srclink2 = srclinks[1]\n",
    "    print('number of chants in', srclink2, siglum, ':', len(chants[chants['srclink'] == srclink2]))\n",
    "    print('---------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4339bd6d",
   "metadata": {},
   "source": [
    "**A-KN CCl 1018** - TWO different books having the same sigla on URL pages - in CDB and A4M - probably A4M one is a piece of parchment inserted inside book referd to by CDB  \n",
    "**SK-KRE Tom. 2, Fons 41, Fasc. 1, Nro. 3, 1601** - two parts of the same book with separate URL entries  \n",
    "**SK-KRE Tom. 1, Fons 32, Fasc. 9, Nro. 83, 1583** - two parts of the same book with separate URL entries  \n",
    "**PL-PŁsem MsEPl 12** - two parts of the same book with separate URL entries  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c50a2b",
   "metadata": {},
   "source": [
    "##### Very \"data version\" specific piece of code follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6c3784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-LA Caixa 2, Fragmento 017\n",
      "number of chants in manuscripts: 8 8\n",
      "size of interesection: 8\n",
      "\n",
      "VI G 3a, folios in HYM & not in FCB: set()\n",
      "VI G 3a, folios in HYM & in FCB: {'111r', '110r', '106r', '097r', '112v', '109v', '108r', '056r', '104v', '102r', '113v', '097v', '104r', '107v', '108v', '106v', '062v', '114v', '099r', '096v', '105v', '112r', '105r', '101v', '114r', '102v', '099v', '109r', '103r', '110v', '101r', '103v'}\n",
      "\n",
      "XII A 24, folios in HYM & not in FCB: set()\n",
      "XII A 24, folios in HYM & in FCB: {'029v', '028v', '001v', '002r', '029r', '028r'}\n",
      "\n",
      "XV A 10, folios in HYM & not in FCB: set()\n",
      "XV A 10, folios in HYM & in FCB: {'040v', '007v', '007r'}\n",
      "\n",
      "XIV G 64, folios in HYM & not in FCB: {'074v', '080r'}\n",
      "XIV G 64, folios in HYM & in FCB: {'116v'}\n",
      "\n",
      "M III 6: FCB: 467 HYM: 156\n",
      "number of folios in HYM that are not in FCB: 112\n",
      "Genres in HYM chants: genre\n",
      "Sq    156\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# And these needs to be inspect on overlaping chant records:\n",
    "# P-LA Caixa 2, Fragmento 017 - https://musicahispanica.eu/source/62316 and https://pemdatabase.eu/source/46528\n",
    "caixa2PEM = chants[chants['srclink'] == \"https://pemdatabase.eu/source/46528\"]\n",
    "caixa2SEMM = chants[chants['srclink'] == \"https://musicahispanica.eu/source/62316\"]\n",
    "print('P-LA Caixa 2, Fragmento 017')\n",
    "print('number of chants in manuscripts:', len(caixa2PEM), len(caixa2SEMM))\n",
    "print('size of interesection:', len(set(caixa2SEMM['cantus_id']).intersection(set(caixa2PEM['cantus_id']))))\n",
    "print()\n",
    "# Both records complete -> we have to discard one of them - in sources as well as in chants...\n",
    "\n",
    "# CZ-Pu VI G 3a - https://hymnologica.cz/source/5364 and https://cantusbohemiae.cz/source/9147\n",
    "viFCB = chants[chants['srclink'] == \"https://cantusbohemiae.cz/source/9147\"]\n",
    "viHYM = chants[chants['srclink'] == \"https://hymnologica.cz/source/5364\"]\n",
    "print('VI G 3a, folios in HYM & not in FCB:', set(viHYM[['folio', 'cantus_id']]).difference(set(viFCB[['folio', 'cantus_id']])))\n",
    "print('VI G 3a, folios in HYM & in FCB:', set(viHYM['folio']).intersection(set(viFCB['folio'])))\n",
    "vi_dupl_folios_cids = set(zip(viHYM['folio'], viHYM['cantus_id'])).intersection(set(zip(viFCB['folio'], viFCB['cantus_id'])))\n",
    "print()\n",
    "# CZ-Pn XII A 24 https://hymnologica.cz/source/10619  and https://cantusbohemiae.cz/source/33177\n",
    "xiiFCB = chants[chants['srclink'] == \"https://cantusbohemiae.cz/source/33177\"]\n",
    "xiiHYM = chants[chants['srclink'] == \"https://hymnologica.cz/source/10619\"]\n",
    "print('XII A 24, folios in HYM & not in FCB:', set(xiiHYM['folio']).difference(set(xiiFCB['folio'])))\n",
    "print('XII A 24, folios in HYM & in FCB:', set(xiiHYM['folio']).intersection(set(xiiFCB['folio'])))\n",
    "xii_dupl_folios_cids = set(zip(xiiHYM['folio'], xiiHYM['cantus_id'])).intersection(set(zip(xiiFCB['folio'], xiiFCB['cantus_id'])))\n",
    "print()\n",
    "# CZ-Pn XV A 10 - https://hymnologica.cz/source/47  and https://cantusbohemiae.cz/source/28509\n",
    "xvFCB = chants[chants['srclink'] == \"https://cantusbohemiae.cz/source/28509\"]\n",
    "xvHYM = chants[chants['srclink'] == \"https://hymnologica.cz/source/47\"]\n",
    "print('XV A 10, folios in HYM & not in FCB:', set(xvHYM['folio']).difference(set(xvFCB['folio'])))\n",
    "print('XV A 10, folios in HYM & in FCB:', set(xvHYM['folio']).intersection(set(xvFCB['folio'])))\n",
    "xv_dupl_folios_cids = set(zip(xvHYM['folio'], xvHYM['cantus_id'])).intersection(set(zip(xvFCB['folio'], xvFCB['cantus_id'])))\n",
    "print()\n",
    "# CZ-Pu XIV G 46 - https://hymnologica.cz/source/5366 and https://cantusbohemiae.cz/source/9194\n",
    "xivFCB = chants[chants['srclink'] == \"https://cantusbohemiae.cz/source/9194\"]\n",
    "xivHYM = chants[chants['srclink'] == \"https://hymnologica.cz/source/5366\"]\n",
    "print('XIV G 64, folios in HYM & not in FCB:', set(xivHYM['folio']).difference(set(xivFCB['folio'])))\n",
    "print('XIV G 64, folios in HYM & in FCB:', set(xivHYM['folio']).intersection(set(xivFCB['folio'])))\n",
    "xiv_dupl_folios_cids = set(zip(xivHYM['folio'], xivHYM['cantus_id'])).intersection(set(zip(xivFCB['folio'], xivFCB['cantus_id'])))\n",
    "print()\n",
    "# CZ-OLu M III 6 - https://hymnologica.cz/source/6983 and https://cantusbohemiae.cz/source/11616\n",
    "iiiFCB = chants[chants['srclink'] == \"https://cantusbohemiae.cz/source/11616\"]\n",
    "iiiHYM = chants[chants['srclink'] == \"https://hymnologica.cz/source/6983\"]\n",
    "iii_dupl_folios_cids = set(zip(iiiHYM['folio'], iiiHYM['cantus_id'])).intersection(set(zip(iiiFCB['folio'], iiiFCB['cantus_id'])))\n",
    "print('M III 6: FCB:', len(iiiFCB), 'HYM:', len(iiiHYM))\n",
    "print('number of folios in HYM that are not in FCB:', len(set(iiiHYM['folio']).difference(set(iiiFCB['folio']))))\n",
    "print('Genres in HYM chants:', iiiHYM['genre'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4b4ef",
   "metadata": {},
   "source": [
    "#### Troublemakers in duplicite sigla solving\n",
    "P-LA Caixa 2, Fragmento 017  \n",
    "-> lets discard PEM record since SEMM has full_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f77f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard duplicate PEM source - in sources as well as in chants\n",
    "chants = chants[chants['srclink'] != \"https://pemdatabase.eu/source/46528\"]\n",
    "sources = sources[sources['srclink'] != \"https://pemdatabase.eu/source/46528\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197dafd5",
   "metadata": {},
   "source": [
    "FCB 'vs' HYM  \n",
    "- lets keep non-duplicate chants records from both - just change srclink from HYM one to FCB one (but keep HYM chantlink and db)  \n",
    "- discard HYM records in sources  \n",
    "- here we are changing srclinks in data from scraped JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2ffab2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chant records before HYM duplicites discarding: 888102\n",
      "number of chant records after HYM duplicites discarding: 888010\n"
     ]
    }
   ],
   "source": [
    "hymnologica_links = [\n",
    "    \"https://hymnologica.cz/source/5364\",\n",
    "    \"https://hymnologica.cz/source/10619\",\n",
    "    \"https://hymnologica.cz/source/47\",\n",
    "    \"https://hymnologica.cz/source/5366\",\n",
    "    \"https://hymnologica.cz/source/6983\"\n",
    "]\n",
    "# Discard HYM chant records where FCB equivalent exists\n",
    "# we would try to detect this based on folio and cantus_id\n",
    "duplicate_pairs = list(xii_dupl_folios_cids) + list(xiv_dupl_folios_cids) + list(xv_dupl_folios_cids) + list(iii_dupl_folios_cids) + list(vi_dupl_folios_cids)\n",
    "mask = chants.apply(\n",
    "    lambda row: ((row['folio'], row['cantus_id']) in duplicate_pairs) and (row['srclink'] in hymnologica_links),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print('number of chant records before HYM duplicites discarding:', len(chants))\n",
    "# Filter out the rows where mask is True\n",
    "empt_chants = chants[~mask].reset_index(drop=True)\n",
    "print('number of chant records after HYM duplicites discarding:', len(empt_chants))\n",
    "chants = empt_chants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8cb8330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change HYM srclinks to FCB once in chants\n",
    "chants.loc[chants['srclink'] == \"https://hymnologica.cz/source/5364\", 'srclink'] = \"https://cantusbohemiae.cz/source/9147\"\n",
    "chants.loc[chants['srclink'] == \"https://hymnologica.cz/source/10619\", 'srclink'] = \"https://cantusbohemiae.cz/source/33177\"\n",
    "chants.loc[chants['srclink'] == \"https://hymnologica.cz/source/47\", 'srclink'] = \"https://cantusbohemiae.cz/source/28509\"\n",
    "chants.loc[chants['srclink'] == \"https://hymnologica.cz/source/5366\", 'srclink'] = \"https://cantusbohemiae.cz/source/9194\"\n",
    "chants.loc[chants['srclink'] == \"https://hymnologica.cz/source/6983\", 'srclink'] = \"https://cantusbohemiae.cz/source/11616\"\n",
    "\n",
    "# Discard HYM sources in sources\n",
    "sources = sources[~sources['srclink'].isin(hymnologica_links)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d27faf",
   "metadata": {},
   "source": [
    "### Numerical century\n",
    "For better computational processing, we decided to add a new column to source records - numerical century = integer representing century of origin based on what is filled in the century field.  \n",
    "(Again, general code follows.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5fc3b681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c5d4bcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical century\n",
    "def get_numerical_century(century : str) -> int:\n",
    "    \"\"\"\n",
    "    Extracts the numerical century from a string representation of a century.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Go for years first\n",
    "        four_digits_pattern = r'(?<!\\d)\\d{4}(?!\\d)'\n",
    "        four_digits_match = re.findall(four_digits_pattern, century)\n",
    "        if four_digits_match is not None:\n",
    "            if len(four_digits_match) == 1:\n",
    "                return int(four_digits_match[0][0:2])+1\n",
    "            elif len(four_digits_match) > 1: \n",
    "                # take first founded number anyway\n",
    "                return int(four_digits_match[0][0:2])+1\n",
    "        # Ideally catches cases like \"12th century\" or \"08th century\"\n",
    "        two_digits_pattern = r'(?<!\\d)\\d{2}(?!\\d)'\n",
    "        two_digits_match = re.findall(two_digits_pattern, century)\n",
    "        if len(two_digits_match) == 1:\n",
    "            return int(two_digits_match[0])\n",
    "        elif len(two_digits_match) > 1: \n",
    "            # take first anyway\n",
    "            return int(two_digits_match[0])\n",
    "        # For the case of single digit centuries like \"9th century\"\n",
    "        one_digit_pattern = r'(?<!\\d)\\d{1}(?!\\d)'\n",
    "        one_digit_match = re.findall(one_digit_pattern, century)\n",
    "        if len(one_digit_match) == 1:\n",
    "            return int(one_digit_match[0])\n",
    "    \n",
    "        # If we reach here, we did not find a century - REPORT\n",
    "        print('PROBLEM:', century)\n",
    "    except: # probably nan coming\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a3d87142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply numerical century creation on data about sources\n",
    "sources['num_century'] = sources['century'].apply(get_numerical_century)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b3466c",
   "metadata": {},
   "source": [
    "### Cursus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f91c1e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sources: 2266\n",
      "\n",
      "distribution of cursus values in sources:\n",
      "cursus\n",
      "Secular      196\n",
      "Monastic      86\n",
      "cathedral     49\n",
      "unknown       35\n",
      "Romanum       14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('number of sources:', len(sources))\n",
    "print()\n",
    "print('distribution of cursus values in sources:')\n",
    "print(sources['cursus'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc05217d",
   "metadata": {},
   "source": [
    "### Provenance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "386c3d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of provenance values in data: 642\n",
      "\n",
      "15 most common provenance values in data:\n",
      "provenance\n",
      "Slovakia                                       110\n",
      "Bohemia                                         63\n",
      "Klosterneuburg                                  63\n",
      "Hungary                                         57\n",
      "Austria/Germany                                 44\n",
      "Austria                                         44\n",
      "Central Europe                                  40\n",
      "Germany                                         30\n",
      "medieval Hungary                                28\n",
      "Italy                                           24\n",
      "Augsburg                                        22\n",
      "Hungary (Spiš region)                           20\n",
      "St Gallen                                       20\n",
      "Moravia/ Slovakia: Nové Mesto nad Váhom (?)     16\n",
      "Bratislava                                      16\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('number of provenance values in data:', len(set(sources['provenance'])))\n",
    "print('\\n15 most common provenance values in data:')\n",
    "print(sources['provenance'].value_counts().head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf978769",
   "metadata": {},
   "source": [
    "## Throw away not used fields\n",
    "We have quite a lot fields in our data - mostly a legacy of CantusCorpus v0.2 (Bas Cornelissen, 2020), that was based only on CDB - that are empty, which we would like to get rid of as part of this data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "788d5844",
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_columns_chants = ['corpus_id', 'finalis', 'differentia', 'marginalia', \n",
    "                          'cao_concordances', 'notes', 'dataset_name', 'dataset_idx',\n",
    "                          'full_text_manuscript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "420db315",
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_columns_sources = ['image_link', 'n_cantus_chants', 'n_cantus_melodies', 'provenance_detail',\n",
    "                           'segment','summary', 'indexing_notes', 'liturgical_occasions', 'indexing_date',\n",
    "                           'description', 'rism', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f9d4c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard selected empty columns in chants\n",
    "for col in discard_columns_chants:\n",
    "    if col in chants.columns:\n",
    "        chants.drop(columns=[col], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3161e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard selected empty columns in sources\n",
    "for col in discard_columns_sources:\n",
    "    if col in sources.columns:\n",
    "        sources.drop(columns=[col], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f9552b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename image_link to image to link with pycantus and CI API names\n",
    "chants.rename(columns={'image_link': 'image'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "45768171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'volpiano' to 'melody' to link with pycantus and CI API names\n",
    "chants.rename(columns={'volpiano': 'melody'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7d39ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "chants.drop(columns=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "28ab1524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['chantlink', 'incipit', 'cantus_id', 'mode', 'siglum', 'position',\n",
      "       'folio', 'sequence', 'feast', 'feast_code', 'genre', 'office',\n",
      "       'srclink', 'melody_id', 'full_text', 'melody', 'db', 'image'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(chants.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6c3954",
   "metadata": {},
   "source": [
    "## Store what we have done\n",
    "(Do not forget then to add manually 12 Hispanica fragments after storing sources => or simply anything you decided to do manually.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a97cfd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save chants after all changes\n",
    "chants.to_csv(FINAL_CHANTS_CSV_PATH, index=False)\n",
    "# Save sources after all changes\n",
    "sources.to_csv(FINAL_SOURCES_CSV_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
