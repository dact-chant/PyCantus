{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89528838",
   "metadata": {},
   "source": [
    "# Unseen Chants: how much are we missing?\n",
    "The [Cantus Index](https://cantusindex.org/) database network has been growing for almost 40 years now. Over 800,000 records is... quite a lot. And Gregorian chant is, after all, a finite tradition. Actually, it should be very finite: there are only so many positions for chants in the liturgical calendar, and you are supposed to be using the chants as defined by the Roman Rite, primarily. Places do develop their peculiarities -- local saints, or saints specific to monastic orders, or 'foundations' in the later Middle Ages that paid for a specific feast related e.g. to the profession they represented -- and new feasts were sometimes introduced even to the Roman rite, but in principle chant repertoire was limited.\n",
    "\n",
    "From this follows that as we catalogue more and more sources, at some point we are going to run into 'diminishing returns' in terms of discovering new chant repertoire. That will also mean that the database is already quite representative of all the repertoire that the tradition contained. Of course we will never see everything (also because we only have about 30,000 extant sources from an estimated 500,000-1,500,000 medieval chant manuscripts produced), but when it takes e.g. 1,000 catalogued chants on average to find one for which we have no Cantus ID, we can be pretty sure we represent the repertoire quite well.\n",
    "\n",
    "The problem of guessing how much repertoire we haven't seen yet -- and, conversely, how much we have already documented -- is structurally very similar to the issue that ecologists have when documenting biodiversity. The first paper on this is from 1943. This was a butterfly study in then-British Malaya. They caught a bunch of different butterfly species: from a few species there were a lot of individuals, but a lot of species were rather rare, and the biologist in charge noticed that this meant there must have been a lot of butterfly species which were actually there but were never caught. In order to get a good estimate of the actual butterfly biodiversity in the area, the number of butterfly species that were not observed -- but quite certainly are there -- must be estimated and added to the number of observed species. And this can be a lot -- many species are comparatively rare pretty much anywhere you look. That's sort of the 80-20 rule, and the phenomenon of long-tail distributions (that we saw for instance in the alleluia chants).\n",
    "\n",
    "This class of problems is called the Unseen Species problem. It has been studied extensively in ecology, and analogies were found in other fields such as natural language processing (allocating probability for out-of-vocabulary words in language models) or literary studies (how many words did Shakespeare know?). In many real-world problems the estimated number of unseen species can be greater than the number of observed species.\n",
    "\n",
    "We apply this for the first time to musical data -- Gregorian chant. The basic idea is very simple. Each Cantus ID is a species, and each chant record is like a butterfly caught in a net. We then apply some estimators of how many species we haven't observed yet. This will give us a principled guess of how much repertoire we can still expect to discover.\n",
    "\n",
    "(As with other chant research, we should do this by individual chant genres.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7de3c98",
   "metadata": {},
   "source": [
    "### General code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21815ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycantus.data as data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd87b0",
   "metadata": {},
   "source": [
    "#### Load dataset\n",
    "We are going to use [Cantus Corpus v1.0](https://github.com/DvorakovaA/CantusCorpus/tree/main/cantuscorpus_1.0) dataset, that can be loaded from available datasets of PyCantus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c236555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading chants and sources...\n",
      "Creating missing sources...\n",
      "0 missing sources created!\n",
      "Data loaded!\n",
      "Number of chants in corpus before any processing: 888010\n",
      "Number of sources in corpus before any processing: 2278\n"
     ]
    }
   ],
   "source": [
    "cantuscorpus = data.load_dataset(\"cantuscorpus_v1.0\", load_editable=True, \n",
    "                                  create_missing_sources=True)\n",
    "print(f'Number of chants in corpus before any processing: {len(cantuscorpus.chants)}')\n",
    "print(f'Number of sources in corpus before any processing: {len(cantuscorpus.sources)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dca2fa",
   "metadata": {},
   "source": [
    "## Method 1: The Chao estimator\n",
    "\n",
    "Many Unseen Species estimators exist, but for our purposes we use one by Anne Chao et al. from 1984 (and very nicely re-framed in a 2017 paper from her group). This estimator has the advantage that is is *non-parametric*: it works regardless of the underlying distribution of species (Cantus ID) frequency classes. For instance, with the communio, or antiphon and responsory frequency distributions we were plotting earlier, we don't have to care about those weird bumps in the curve.\n",
    "\n",
    "The estimator is also very simple: all it needs are the count of singletons, and the count of doubletons: how many species only occur once, and how many occur twice in a sample.\n",
    "\n",
    "The actual formula for the Chao1 estimator is:\n",
    "\n",
    "\\begin{align}\n",
    "S = S_{obs} + \\frac{f_1^2}{2 f_2}\n",
    "\\end{align}\n",
    "\n",
    "where $S$ is the total expected number of species, $S_{obs}$ is the number of observed species (Cantus IDs), $f_1$ is the number of Cantus IDs observed once, and $f_2$ is the number of Cantus IDs observed twice.\n",
    "\n",
    "It really is that simple. The reasons *why* such a simple formula works for a pretty hard problem are more complicated, of course, but the intuition is that the approximate shape of the 'long tail' of rare species continues roughly along the same curve one more step further. (Recall the logarithmic zig-zag-ish plots and imagine another step to the bottom right...)\n",
    "\n",
    "A nice constructive proof follows from Good-Turing smoothing of language models, but we won't go into that now. What does follow from the proof, however, is that the Chao1 estimator is a **lower bound**. Under some conditions (when the shape of the 'long tail' observations is representative, which is when the sampling process is done in an unbiased way), it is also an unbiased estimate, but these conditions practically never really happen.\n",
    "\n",
    "So, we have to be careful in interpreting the result of the estimator: if the number that falls out of the formula is e.g. 1225, it does not mean we probably haven't seen 1225 Cantus IDs, give or take. It means that we haven't seen *at least* 1225 Cantus IDs, give or take (there is always some inherent uncertainty).\n",
    "\n",
    "Once we have the estimated $S$, we can also compute the **species coverage**: what proportion of the expected total number of species in the ecosystem -- Cantus IDs -- have we already observed? This is simply done as $S_{obs} / S$. But again we must be careful with the interpretation: since $S$ is a lower bound, this coverage is an **upper bound**. We have seen *at most* $S_{obs} / S$ of the total (bio)diversity of the ecosystem we are sampling from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99583a4",
   "metadata": {},
   "source": [
    "**Abundance and Incidence.**\n",
    "\n",
    "There are two basic settings in which to do unseen species estimates: abundance, and incidence.\n",
    "\n",
    "In case of **abundance**, we count each occurrence of each species and get our $f_1$ and $f_2$ singleton and doubleton counts simply from that.\n",
    "\n",
    "In case we use **incidence**, we instead look at presence or absence of species in a sample. In our case, that would mean we don't care how many times a chant has occured in a source, we only care whether it was there. I think this is a more appropriate model of what is going on in chant data -- it is already pre-structured into individual samples, the samples are roughly comparable (liturgy for a year), and importantly the re-use of a chant in one place multiple times does *not* mean it is more likely that we are also going to see this chant in other sources. (Often, for a feast that is e.g. unique to a source, like a rare local saint, you would see the same antiphon used multiple times within that saint's day.)\n",
    "\n",
    "So, in the incidence-based setting, we would get our $f_1$ as the number of Cantus IDs that only occur in one source, and $f_2$ is the number of Cantus IDs that occurs in two sources. This approach is what we use in this study, and this is also why the term 'incidence' will keep popping up in variable names or function parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67325044",
   "metadata": {},
   "source": [
    "Experiment 1\n",
    "------------\n",
    "\n",
    "Now that we have defined the method, and the material, we can run the 'unseen chants' experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e4ca3",
   "metadata": {},
   "source": [
    "This experiment is from submission of Jan Hajiƒç jr. and Fabian Moss to DLfM 2025 (Knowing when to stop: insights from ecology for building catalogues, collections, and corpora, [arXiv](https://www.arxiv.org/abs/2507.14614)).  \n",
    "This class of models is based off of the work of Kestemont et al., 2022, who did this for Dutch and other chivalric epics. Mike Kestemont and his co-authors implemented this in a convenient Python library called `copia` (from: 'cornucopia'), which we are going to re-use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8719ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/mikekestemont/copia.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e35e5073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the essential functions from Copia\n",
    "from copia.data import to_copia_dataset\n",
    "\n",
    "# Importing useful libraries\n",
    "import numpy as np  # This is an important library for all sorts of fast math.\n",
    "import os           # This is a library for traversing and manipulating the file system.\n",
    "import copy        # This library helps with copying data structures.\n",
    "import collections  # This library has some useful data structures.\n",
    "import pprint     # This library helps with pretty-printing data structures.\n",
    "\n",
    "# Importing useful parts of PyCantus\n",
    "from pycantus.filtration import  Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bdc3fe",
   "metadata": {},
   "source": [
    "We have already loaded all our chant data, we just have to look at how to format them to be able to use the implementation of unseen species estimators that are available in the `copia` library.\n",
    "\n",
    "We will cheat here a little and just tell you that all we need is a list of pairs: `(species, sample)`. In our case, the `species` is the `cantus_id` field of a chant, and the `sample` corresponds to the `source_id` in which we have observed that particular chant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1a14a9",
   "metadata": {},
   "source": [
    "We would like to limit ourselves to the core genres for the Office and Mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90be08f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRES_OFFICE = ['A', 'R', 'V', 'W', 'I']\n",
    "GENRES_MASS_PROPERS = ['In', 'InV', 'Gr', 'GrV', 'Al', 'AlV', 'Of', 'OfV', 'Cm', 'CmV', 'Tc', 'TcV']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5c3a877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made observation lists for 17 genres; 796456 observations total.\n"
     ]
    }
   ],
   "source": [
    "observation_lists_per_genre = {}\n",
    "for genre in GENRES_OFFICE + GENRES_MASS_PROPERS:\n",
    "    # Prepare filter by genre\n",
    "    genre_filter = Filter('filter_'+genre)\n",
    "    genre_filter.add_value_include('genre', genre)\n",
    "    # Apply filter to a copy of the corpus\n",
    "    filtered_corpus = copy.copy(cantuscorpus)\n",
    "    filtered_corpus.apply_filter(genre_filter)\n",
    "    # Now we can make the observation list for this genre\n",
    "    observation_lists_per_genre[genre] = []\n",
    "    for ch in filtered_corpus.chants:\n",
    "        observation_lists_per_genre[genre].append( (ch.cantus_id, ch.srclink) )\n",
    "\n",
    "# Reporting again\n",
    "_total_observations = sum([len(observations_list) for observations_list in observation_lists_per_genre.values()])\n",
    "print('Made observation lists for {} genres; {} observations total.'.format(len(observation_lists_per_genre), _total_observations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085acc9b",
   "metadata": {},
   "source": [
    "What are the basic descriptive statistics for each genre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b33af408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_incidence_statistics(observation_list):\n",
    "    all_species = collections.defaultdict(int)\n",
    "    all_samples = collections.defaultdict(int)\n",
    "    for (sp, sam) in observation_list:\n",
    "        all_species[sp] += 1\n",
    "        all_samples[sam] += 1\n",
    "\n",
    "    n_singletons = len([sp for sp in all_species if all_species[sp] == 1])\n",
    "    #n_doubletons = len([sp for sp in all_species if all_species[sp] == 2])\n",
    "\n",
    "    stats = {\n",
    "        'n_species': len(all_species),\n",
    "        'n_samples': len(all_samples),\n",
    "    }\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f61913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_per_genre = {g: extract_incidence_statistics(observation_lists_per_genre[g])\n",
    "                   for g in observation_lists_per_genre}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb12d3fa",
   "metadata": {},
   "source": [
    "Now that we have observation lists, we can feed them into `copia` and run the unseen species estimators!\n",
    "\n",
    "We first wrap the observation lists with some miscellaneous data structure defined by `copia`. The important part of this is defining the `data_type` as `'incidence'`, to reflect the decision to use incidence rather than abundance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1be65c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "copia_datasets_per_genre = {g: to_copia_dataset(observation_lists_per_genre[g],\n",
    "                                                data_type=\"incidence\",\n",
    "                                                input_type='observation_list',\n",
    "                                                n_sampling_units=1)\n",
    "                            for g in observation_lists_per_genre}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2849af",
   "metadata": {},
   "source": [
    "Copia supports more estimators than just Chao1, and in a bigger study we would want to compare them, so we prepare the function to run different unseen species estimates on the same data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2935cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copia.estimators import diversity\n",
    "# This is the interface copia provides for actually computing the unseen species estimates.\n",
    "\n",
    "\n",
    "def extract_incidence_diversities(incidences,         # The input data, as a copia dataset\n",
    "                                  factor_max_steps=8, # Nevermind this\n",
    "                                  n_iter=20,          # and this\n",
    "                                  step_size=10,       # and this,\n",
    "                                  methods=('chao1', 'ichao1', 'ace', 'jackknife', 'egghe_proot'),   # These are some supported estimators,\n",
    "                                  **kwargs):          # and this.\n",
    "    # We store the results in a dictionary (again, this is the 'shortcut' dictionary construction syntax)\n",
    "    diversities = {method: round(diversity(incidences,\n",
    "                                           method=method))\n",
    "                   for method in methods}\n",
    "    return diversities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb7a9ec",
   "metadata": {},
   "source": [
    "and now we uncermoniously compute just the Chao1 values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5465719",
   "metadata": {},
   "outputs": [],
   "source": [
    "diversities_per_genre = {g: extract_incidence_diversities(copia_datasets_per_genre[g], methods=['chao1'])\n",
    "                         for g in copia_datasets_per_genre}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c045df6",
   "metadata": {},
   "source": [
    "### Results 1\n",
    "\n",
    "Look what we found!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08297c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': {'chao1': 19032},\n",
       " 'R': {'chao1': 8968},\n",
       " 'V': {'chao1': 16018},\n",
       " 'W': {'chao1': 1444},\n",
       " 'I': {'chao1': 981},\n",
       " 'In': {'chao1': 525},\n",
       " 'InV': {'chao1': 1300},\n",
       " 'Gr': {'chao1': 343},\n",
       " 'GrV': {'chao1': 408},\n",
       " 'Al': {'chao1': 1407},\n",
       " 'AlV': {'chao1': 398},\n",
       " 'Of': {'chao1': 387},\n",
       " 'OfV': {'chao1': 580},\n",
       " 'Cm': {'chao1': 384},\n",
       " 'CmV': {'chao1': 951},\n",
       " 'Tc': {'chao1': 141},\n",
       " 'TcV': {'chao1': 417}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diversities_per_genre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4ad059",
   "metadata": {},
   "source": [
    "These numbers are the lower bound on $f_0$, the number of unseen Cantus IDs for each genre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f18e7cb",
   "metadata": {},
   "source": [
    "Now in order to properly understand these numbers, we need to report them in relation to other statistics about each genre. Specifically, we want the coverage, and we want to see how the proportion of unseen Cantus IDs -- basically, the diversity of that genre -- relates to the ratio between the number of distinct Cantus IDs and nubmer of sources containing that genre, which will help illustrate that this measure of diversity is not just a trivial result of this ratio, or \"average density\" of the genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f943a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_for_genre(g, stats, diversities):\n",
    "    g_stats = stats[g]\n",
    "    n_species, n_samples = g_stats['n_species'], g_stats['n_samples']\n",
    "\n",
    "    g_diversities = diversities[g]\n",
    "    g_diversity_ratios = {k: n_species / v for k, v in g_diversities.items()}\n",
    "    diversities_string = ', '.join(['{}: {}\\tcov. (max.): {:.3f}'.format(k, v, g_diversity_ratios[k]) for k, v in g_diversities.items()])\n",
    "\n",
    "    print('{}:\\t{} species\\t{} samples\\t{}'.format(g, n_species, n_samples, diversities_string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53f313db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\t12667 species\t1347 samples\tchao1: 19032\tcov. (max.): 0.666\n",
      "R:\t5790 species\t1088 samples\tchao1: 8968\tcov. (max.): 0.646\n",
      "V:\t9382 species\t1029 samples\tchao1: 16018\tcov. (max.): 0.586\n",
      "W:\t1072 species\t605 samples\tchao1: 1444\tcov. (max.): 0.742\n",
      "I:\t658 species\t455 samples\tchao1: 981\tcov. (max.): 0.671\n",
      "In:\t350 species\t527 samples\tchao1: 525\tcov. (max.): 0.667\n",
      "InV:\t796 species\t427 samples\tchao1: 1300\tcov. (max.): 0.612\n",
      "Gr:\t229 species\t522 samples\tchao1: 343\tcov. (max.): 0.668\n",
      "GrV:\t292 species\t476 samples\tchao1: 408\tcov. (max.): 0.716\n",
      "Al:\t946 species\t506 samples\tchao1: 1407\tcov. (max.): 0.672\n",
      "AlV:\t101 species\t190 samples\tchao1: 398\tcov. (max.): 0.254\n",
      "Of:\t276 species\t501 samples\tchao1: 387\tcov. (max.): 0.713\n",
      "OfV:\t416 species\t236 samples\tchao1: 580\tcov. (max.): 0.717\n",
      "Cm:\t320 species\t501 samples\tchao1: 384\tcov. (max.): 0.833\n",
      "CmV:\t664 species\t89 samples\tchao1: 951\tcov. (max.): 0.698\n",
      "Tc:\t111 species\t285 samples\tchao1: 141\tcov. (max.): 0.787\n",
      "TcV:\t343 species\t262 samples\tchao1: 417\tcov. (max.): 0.823\n"
     ]
    }
   ],
   "source": [
    "for g in diversities_per_genre:\n",
    "  report_for_genre(g, stats_per_genre, diversities_per_genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af825928",
   "metadata": {},
   "source": [
    "It would be better to report these results separately by type of liturgy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94ee7550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Office genre diversities\n",
      "A:\t12667 species\t1347 samples\tchao1: 19032\tcov. (max.): 0.666\n",
      "R:\t5790 species\t1088 samples\tchao1: 8968\tcov. (max.): 0.646\n",
      "V:\t9382 species\t1029 samples\tchao1: 16018\tcov. (max.): 0.586\n",
      "W:\t1072 species\t605 samples\tchao1: 1444\tcov. (max.): 0.742\n",
      "I:\t658 species\t455 samples\tchao1: 981\tcov. (max.): 0.671\n",
      "\n",
      "\n",
      "Mass genre diversities\n",
      "In:\t350 species\t527 samples\tchao1: 525\tcov. (max.): 0.667\n",
      "InV:\t796 species\t427 samples\tchao1: 1300\tcov. (max.): 0.612\n",
      "Gr:\t229 species\t522 samples\tchao1: 343\tcov. (max.): 0.668\n",
      "GrV:\t292 species\t476 samples\tchao1: 408\tcov. (max.): 0.716\n",
      "Al:\t946 species\t506 samples\tchao1: 1407\tcov. (max.): 0.672\n",
      "AlV:\t101 species\t190 samples\tchao1: 398\tcov. (max.): 0.254\n",
      "Of:\t276 species\t501 samples\tchao1: 387\tcov. (max.): 0.713\n",
      "OfV:\t416 species\t236 samples\tchao1: 580\tcov. (max.): 0.717\n",
      "Cm:\t320 species\t501 samples\tchao1: 384\tcov. (max.): 0.833\n",
      "CmV:\t664 species\t89 samples\tchao1: 951\tcov. (max.): 0.698\n",
      "Tc:\t111 species\t285 samples\tchao1: 141\tcov. (max.): 0.787\n",
      "TcV:\t343 species\t262 samples\tchao1: 417\tcov. (max.): 0.823\n"
     ]
    }
   ],
   "source": [
    "print('Office genre diversities')\n",
    "for g in GENRES_OFFICE:\n",
    "  report_for_genre(g, stats_per_genre, diversities_per_genre)\n",
    "\n",
    "print('\\n')   # Just an empty line\n",
    "print('Mass genre diversities')\n",
    "for g in GENRES_MASS_PROPERS:\n",
    "  report_for_genre(g, stats_per_genre, diversities_per_genre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d60d1cf",
   "metadata": {},
   "source": [
    "And we should actually also include results for the aggregated chants of all genres for a given liturgy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a59448d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_observations_list = []\n",
    "for g in GENRES_MASS_PROPERS:\n",
    "    mass_observations_list.extend(observation_lists_per_genre[g])\n",
    "office_observations_list = []\n",
    "for g in GENRES_OFFICE:\n",
    "    office_observations_list.extend(observation_lists_per_genre[g])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29ec964",
   "metadata": {},
   "source": [
    "Because it would be a bit annoying to type out all the individual steps for running the experiment, we can re-write the whole experiment in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d4c3529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_result_from_observations_list(observations_list,\n",
    "                                          n_bootstrap=None):\n",
    "    \"\"\"If n_boostrap > 0, the results will be lists for each key (n_species, n_samples, chao1, coverage)\"\"\"\n",
    "    # Copia has some bug in incidence bootstrapping.\n",
    "    # CI = False\n",
    "    # if n_iter and (n_iter > 1):\n",
    "    #     CI = True\n",
    "    result = {}\n",
    "\n",
    "    # No bootstrapping\n",
    "    stats = extract_incidence_statistics(observations_list)\n",
    "    copia_dataset = to_copia_dataset(observations_list,\n",
    "                                      data_type=\"incidence\",\n",
    "                                      input_type='observation_list',\n",
    "                                      n_sampling_units=1)\n",
    "    diversities = extract_incidence_diversities(copia_dataset,\n",
    "                                                methods=['chao1'],\n",
    "                                                CI=False)\n",
    "\n",
    "    coverage = stats['n_species'] / diversities['chao1']\n",
    "    result = {}\n",
    "    for k, v in stats.items(): result[k] = v\n",
    "    for k, v in diversities.items(): result[k] = v\n",
    "    result['coverage'] = coverage\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d40c30",
   "metadata": {},
   "source": [
    "...and then running the whole experiment from an observations list becomes a single line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "524f14c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mass results: {'chao1': 6471,\n",
      " 'coverage': 0.7241539174779786,\n",
      " 'n_samples': 779,\n",
      " 'n_species': 4686}\n",
      "\n",
      "\n",
      "Office results: {'chao1': 45676,\n",
      " 'coverage': 0.6436202819861634,\n",
      " 'n_samples': 1549,\n",
      " 'n_species': 29398}\n"
     ]
    }
   ],
   "source": [
    "mass_results = compute_result_from_observations_list(mass_observations_list)\n",
    "print('Mass results: {}'.format(pprint.pformat(mass_results)))\n",
    "print('\\n')\n",
    "office_results = compute_result_from_observations_list(office_observations_list)\n",
    "print('Office results: {}'.format(pprint.pformat(office_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f573e7",
   "metadata": {},
   "source": [
    "### Discussion 1\n",
    "\n",
    "What we can immediately notice is that while there is orders of magnitude fewer records for mass propers, the upper bound on coverage is higher (0.72) than for the office (0.64). This tracks with the observation from chant scholarship that mass repertoire is much more fixed -- less diverse -- than repertoire for the office. In terms of documenting chant diversity, the focus of the Cantus Database on cataloguing office sources is well placed: there is apparently more to find there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9be83deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Office genre diversities\n",
      "A:\t12667 species\t1347 samples\tchao1: 19032\tcov. (max.): 0.666\n",
      "R:\t5790 species\t1088 samples\tchao1: 8968\tcov. (max.): 0.646\n",
      "V:\t9382 species\t1029 samples\tchao1: 16018\tcov. (max.): 0.586\n",
      "W:\t1072 species\t605 samples\tchao1: 1444\tcov. (max.): 0.742\n",
      "I:\t658 species\t455 samples\tchao1: 981\tcov. (max.): 0.671\n",
      "\n",
      "\n",
      "Mass genre diversities\n",
      "In:\t350 species\t527 samples\tchao1: 525\tcov. (max.): 0.667\n",
      "InV:\t796 species\t427 samples\tchao1: 1300\tcov. (max.): 0.612\n",
      "Gr:\t229 species\t522 samples\tchao1: 343\tcov. (max.): 0.668\n",
      "GrV:\t292 species\t476 samples\tchao1: 408\tcov. (max.): 0.716\n",
      "Al:\t946 species\t506 samples\tchao1: 1407\tcov. (max.): 0.672\n",
      "AlV:\t101 species\t190 samples\tchao1: 398\tcov. (max.): 0.254\n",
      "Of:\t276 species\t501 samples\tchao1: 387\tcov. (max.): 0.713\n",
      "OfV:\t416 species\t236 samples\tchao1: 580\tcov. (max.): 0.717\n",
      "Cm:\t320 species\t501 samples\tchao1: 384\tcov. (max.): 0.833\n",
      "CmV:\t664 species\t89 samples\tchao1: 951\tcov. (max.): 0.698\n",
      "Tc:\t111 species\t285 samples\tchao1: 141\tcov. (max.): 0.787\n",
      "TcV:\t343 species\t262 samples\tchao1: 417\tcov. (max.): 0.823\n"
     ]
    }
   ],
   "source": [
    "# We re-print the per-genre report, just for convenience\n",
    "print('Office genre diversities')\n",
    "for g in GENRES_OFFICE:\n",
    "  report_for_genre(g, stats_per_genre, diversities_per_genre)\n",
    "\n",
    "print('\\n')   # Just an empty line\n",
    "print('Mass genre diversities')\n",
    "for g in GENRES_MASS_PROPERS:\n",
    "  report_for_genre(g, stats_per_genre, diversities_per_genre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c9c106",
   "metadata": {},
   "source": [
    "While the office genres show a similar level of diversity, for genres of mass propers the upper bound on coverage fluctuates *wildly*. Even though alleluias are typically considered to be the most diverse of the main mass proper genres (i.e. without taking verses into account), we get a coverage up to 0.672. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae08255",
   "metadata": {},
   "source": [
    "## Method 2: Accumulation curve\n",
    "\n",
    "The **accumulation curve** tracks the relationship between how many specimen we have observed, and how many species in total we have seen. This is typically a concave function -- at the beginning, almost every specimen is from a species we haven't seen yet, so the accumulation curve grows very quickly. But as we keep sampling, probably we run into the pesky frequent species over and over, and even the somewhat less frequent ones we will have already seen many times, so the interval between finding new species is going to increase. This is the point of 'diminishing returns' of the cataloguing effort, in terms of diversity.\n",
    "\n",
    "So, have we actually reached the point of diminishing returns? How many new \"species\" can we expect per e.g. 100 catalogued chants? (Or: what is the probability that the next chant we catalogue will require a new Cantus ID?)\n",
    "\n",
    "Fortunately, the Cantus database does record for many of its sources the indexing year, so we can actually reconstruct the empirical accumulation curve, and we can track the probability of encountering a new species when cataloguing over time. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
